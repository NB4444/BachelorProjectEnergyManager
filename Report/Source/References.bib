@article{Ma2009,
abstract = {In recent years, more and more transistors have been integrated within the GPU, which has resulted in steadily rising power consumption requirements. In this paper we present a preliminary scheme to statistically analyze and model the power consumption of amainstream GPU (NVidia GeForce 8800gt) by exploiting the innate coupling among power consumption characteristics, runtime performance, and dynamic workloads. Based on the recorded run-time GPU workload signals, our trained statistical model is capable of robustly and accurately predict- ing power consumption of the target GPU. To the best of our knowledge, this study is the first work that applies statistical analysis to model the power consumption of a mainstream GPU, and its results provide useful insights for future endeavors of building energy-efficient GPU computing paradigms.},
author = {Ma, Xiaohan and Zhong, Lin},
file = {:home/qub1-creation/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Zhong - 2009 - Statistical Power Consumption Analysis and Modeling for GPU-based Computing.pdf:pdf},
journal = {Proceedings of the SOSP Workshop on Power Aware Computing and Systems (HotPower '09)},
mendeley-groups = {Master Project/Selected},
pages = {None},
title = {{Statistical Power Consumption Analysis and Modeling for GPU-based Computing}},
url = {https://www.yecl.org/publications/ma09hotpower.pdf http://www.sigops.org/sosp/sosp09/hotpower.html},
year = {2009}
}

@inproceedings{Chen2011,
abstract = {Graphics Processing Units (GPUs) have emerged as a promising platform for parallel computation. With a large number of scalar processors and abundant memory bandwidth, GPUs provide substantial computation power. While delivering high computation performance, the GPU also consumes high power and needs to be equipped with sufficient power supplies and cooling systems. Therefore, it is essential to institute an efficient mechanism for evaluating and understanding the power consumption requirement when running real applications on high-end GPUs. In this paper, we present a high-level GPU power consumption model using sophisticated tree-based random forest methods which can correlate the power consumption with a set of independent performance variables. This statistical model not only predicts the GPU runtime power consumption accurately, but more importantly, it also provides sufficient insights for understanding the dependence between the GPU runtime power consumption and the individual performance metrics. In order to gain more insights, we use a GPU simulator that can collect more runtime performance metrics than hardware counters. We measure the power consumption of a wide-range of CUDA kernels on an experimental system with GTX 280 GPU as statistical samples for our power analysis. This methodology can certainly be applied to any other CUDA GPU. {\textcopyright} 2011 IEEE.},
author = {Chen, Jianmin and Li, Bin and Zhang, Ying and Peng, Lu and Peir, Jih Kwon},
booktitle = {2011 International Green Computing Conference and Workshops, IGCC 2011},
doi = {10.1109/IGCC.2011.6008582},
file = {:home/qub1-creation/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2011 - Statistical GPU power analysis using tree-based methods.pdf:pdf},
isbn = {9781457712203},
mendeley-groups = {Master Project/Selected},
title = {{Statistical GPU power analysis using tree-based methods}},
year = {2011}
}

@misc{NVIDIA,
author = {NVIDIA},
mendeley-groups = {Master Project/Selected},
title = {{NVIDIA System Management Interface | NVIDIA Developer}},
url = {https://developer.nvidia.com/nvidia-system-management-interface},
urldate = {2020-07-18}
}

@inproceedings{Bakhoda2009,
abstract = {Modern Graphic Processing Units (GPUs) provide sufficiently flexible programming models that understanding their performance can provide insight in designing tomorrow's manycore processors, whether those are GPUs or otherwise. The combination of multiple, multithreaded, SIMD cores makes studying these GPUs useful in understanding tradeoffs among memory, data, and thread level parallelism. While modern GPUs offer orders of magnitude more raw computing power than contemporary CPUs, many important applications, even those with abundant data level parallelism, do not achieve peak performance. This paper characterizes several non-graphics applications written in NVIDIA's CUDA programming model by running them on a novel detailed microarchitecture performance simulator that runs NVIDIA's parallel thread execution (PTX) virtual instruction set. For this study, we selected twelve non-trivial CUDA applications demonstrating varying levels of performance improvement on GPU hardware (versus a CPU-only sequential version of the application). We study the performance of these applications on our GPU performance simulator with configurations comparable to contemporary high-end graphics cards. We characterize the performance impact of several microarchitecture design choices including choice of interconnect topology, use of caches, design of memory controller, parallel workload distribution mechanisms, and memory request coalescing hardware. Two observations we make are (1) that for the applications we study, performance is more sensitive to interconnect bisection bandwidth rather than latency, and (2) that, for some applications, running fewer threads concurrently than on-chip resources might otherwise allow can improve performance by reducing contention in the memory system. {\textcopyright} 2009 IEEE.},
author = {Bakhoda, Ali and Yuan, George L and Fung, Wilson W.L. and Wong, Henry and Aamodt, Tor M},
booktitle = {ISPASS 2009 - International Symposium on Performance Analysis of Systems and Software},
doi = {10.1109/ISPASS.2009.4919648},
file = {:home/qub1-creation/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakhoda et al. - Unknown - Analyzing CUDA Workloads Using a Detailed GPU Simulator.pdf:pdf},
isbn = {9781424441846},
mendeley-groups = {Master Project/Selected},
pages = {163--174},
title = {{Analyzing CUDA workloads using a detailed GPU simulator}},
url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2017/02/gpgpusim.ispass09-2.pdf},
year = {2009}
}

@misc{Russel,
author = {Russel, Daniel M.},
mendeley-groups = {Master Project/Selected},
title = {{Google Advanced Search Operators}},
url = {https://docs.google.com/document/d/1ydVaJJeL1EYbWtlfj9TPfBTE5IBADkQfZrQaBZxqXGs},
urldate = {2020-07-19}
}

@inproceedings{Jiao2010,
abstract = {Nowadays Graphic Processing Units (GPU) are gaining increasing popularity in high performance computing (HPC). While modern GPUs can offer much more computational power than CPUs, they also consume much more power. Energy efficiency is one of the most important factors that will affect a broader adoption of GPUs in HPC. In this paper, we systematically characterize the power and energy efficiency of GPU computing. Specifically, using three different applications with various degrees of compute and memory intensiveness, we investigate the correlation between power consumption and different computational patterns under various voltage and frequency levels. Our study revealed that energy saving mechanisms on GPUs behave considerably different than CPUs. The characterization results also suggest possible ways to improve the "greenness" of GPU computing. {\textcopyright} 2010 IEEE.},
author = {Jiao, Y and Lin, H and Balaji, P and Feng, W},
booktitle = {Proceedings - 2010 IEEE/ACM International Conference on Green Computing and Communications, GreenCom 2010, 2010 IEEE/ACM International Conference on Cyber, Physical and Social Computing, CPSCom 2010},
doi = {10.1109/GreenCom-CPSCom.2010.143},
file = {:home/qub1-creation/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiao et al. - Unknown - Power and Performance Characterization of Computational Kernels on the GPU.pdf:pdf},
isbn = {9780769543314},
mendeley-groups = {Master Project/Selected},
pages = {221--228},
title = {{Power and performance characterization of computational kernels on the GPU}},
url = {https://research.cs.vt.edu/synergy/pubs/papers/yang-perf-power-GPU-DVFS-greencom10.pdf},
year = {2010}
}

@inproceedings{Komoda2013,
abstract = {Future computer systems are built under much stringent power budget due to the limitation of power delivery and cooling systems. To this end, sophisticated power management techniques are required. Power capping is a technique to limit the power consumption of a system to the predetermined level, and has been extensively studied in homogeneous systems. However, few studies about the power capping of CPU-GPU heterogeneous systems have been done yet. In this paper, we propose an efficient power capping technique through coordinating DVFS and task mapping in a single computing node equipped with GPUs. In CPU-GPU heterogeneous systems, settings of the device frequencies have to be considered with task mapping between the CPUs and the GPUs because the frequency scaling can incurs load imbalance between them. To guide the settings of DVFS and task mapping for avoiding power violation and the load imbalance, we develop new empirical models of the performance and the maximum power consumption of a CPU-GPU heterogeneous system. The models enable us to set near-optimal settings of the device frequencies and the task mapping in advance of the application execution. We evaluate the proposed technique with five data-parallel applications on a machine equipped with a single CPU and a single GPU. The experimental result shows that the performance achieved by the proposed power capping technique is comparable to the ideal one. {\textcopyright} 2013 IEEE.},
author = {Komoda, Toshiya and Hayashi, Shingo and Nakada, Takashi and Miwa, Shinobu and Nakamura, Hiroshi},
booktitle = {2013 IEEE 31st International Conference on Computer Design, ICCD 2013},
doi = {10.1109/ICCD.2013.6657064},
file = {:home/qub1-creation/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Komoda et al. - Unknown - Power Capping of CPU-GPU Heterogeneous Systems through Coordinating DVFS and Task Mapping.pdf:pdf},
isbn = {9781479929870},
keywords = {DVFS,GPGPU,Power Capping,Task Mapping},
mendeley-groups = {Master Project/Selected},
pages = {349--356},
title = {{Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping}},
url = {http://www.cse.chalmers.se/{~}sica/phd/mappingstudy/primarystudies/S114.pdf},
year = {2013}
}
